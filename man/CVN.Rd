% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CVN.R
\name{CVN}
\alias{CVN}
\title{Estimating a Covariate-Varying Network (CVN)}
\usage{
CVN(
  data,
  W,
  lambda1 = 1:2,
  lambda2 = 1:2,
  gamma1 = NULL,
  gamma2 = NULL,
  rho = 1,
  eps = 1e-04,
  maxiter = 100,
  truncate = 1e-05,
  rho_genlasso = 1,
  eps_genlasso = 1e-10,
  maxiter_genlasso = 100,
  truncate_genlasso = 1e-04,
  n_cores = min(length(lambda1) * length(lambda2), detectCores() - 1),
  normalized = FALSE,
  warmstart = TRUE,
  minimal = FALSE,
  gamma_ebic = 0.5,
  verbose = TRUE
)
}
\arguments{
\item{data}{A list with matrices, each entry associated with a single graph.
The number of columns should be the same for each matrix.
Number of observations can differ}

\item{W}{The \eqn{(m \times m)}-dimensional symmetric
weight matrix \eqn{W}}

\item{lambda1}{Vector with different \eqn{\lambda_1}. LASSO penalty terms
(Default: \code{1:2})}

\item{lambda2}{Vector with different \eqn{\lambda_2}. The global smoothing parameter values
(Default: \code{1:2})}

\item{gamma1}{A vector of \eqn{\gamma_1}'s LASSO penalty terms, where
\eqn{\gamma_1 = \frac{2 \lambda_1}{m p (1 - p)}}. If \code{gamma1}
is set, the value of \code{lambda1} is ignored. (Default: \code{NULL}).}

\item{gamma2}{A vector of \eqn{\gamma_2}'s global smoothing parameters, where
that \eqn{\gamma_2 = \frac{4 \lambda_2}{m(m-1)p(p-1)}}. If \code{gamma2}
is set, the value of \code{lambda2} is ignored.(Default: \code{NULL}).}

\item{rho}{The \eqn{\rho} penalty parameter for the global ADMM algorithm (Default: \code{1})}

\item{eps}{If the relative difference between two update steps is
smaller than \eqn{\epsilon}, the algorithm stops.
(Default: \code{1e-4})}

\item{maxiter}{Maximum number of iterations (Default: \code{100})}

\item{truncate}{All values of the final \eqn{\hat{\Theta}_i}'s below \code{truncate} will be
set to \code{0}. (Default: \code{1e-5})}

\item{rho_genlasso}{The \eqn{\rho} penalty parameter for the ADMM algorithm
used to solve the generalized LASSO (Default: \code{1})}

\item{eps_genlasso}{If the relative difference between two update steps is
smaller than \eqn{\epsilon}, the algorithm stops.
(Default: \code{1e-10})}

\item{maxiter_genlasso}{Maximum number of iterations for solving
the generalized LASSO problem (Default: \code{100})}

\item{truncate_genlasso}{All values of the final \eqn{\hat{\beta}} below
\code{truncate_genlasso} will be set to \code{0}.
(Default: \code{1e-4})}

\item{n_cores}{Number of cores used (Default: max. number of cores - 1, or
the total number penalty term pairs if that is less)}

\item{normalized}{Data is normalized if \code{TRUE}. Otherwise the data is only
centered (Default: \code{FALSE})}

\item{warmstart}{If \code{TRUE}, use the \code{\link[glasso]{glasso}} package for estimating
the individual graphs first (Default: \code{TRUE})}

\item{minimal}{If \code{TRUE}, the returned \code{cvn} is minimal in terms of
memory, i.e., \code{Theta}, \code{data} and \code{Sigma} are not
returned (Default: \code{FALSE})}

\item{gamma_ebic}{Gamma value for the eBIC (Default: 0.5)}

\item{verbose}{Verbose (Default: \code{TRUE})}
}
\value{
A \code{CVN} object containing the estimates for all the graphs
for each different value of \eqn{(\lambda_1, \lambda_2)}. General results for
the different values of \eqn{(\lambda_1, \lambda_2)} can be found in the data frame
\code{results}. It consists of multiple columns, namely:
\item{\code{id}}{The id. This corresponds to the indices of the lists}
\item{\code{lambda1}}{\eqn{\lambda_1} value}
\item{\code{lambda2}}{\eqn{\lambda_2} value}
\item{\code{gamma1}}{\eqn{\gamma_1} value}
\item{\code{gamma2}}{\eqn{\gamma_2} value}
\item{\code{converged}}{whether algorithm converged or not}
\item{\code{value}}{value of the negative log-likelihood function}
\item{\code{n_iterations}}{number of iterations of the ADMM}
\item{\code{aic}}{Akaike information criterion}
\item{\code{bic}}{Bayesian information criterion}
\item{\code{ebic}}{Extended Bayesian information criterion}
\item{\code{edges_median}}{Median number of edges across the m estimated graphs}
\item{\code{edges_iqr}}{Interquartile range of edges across the m estimated graphs}
The estimates of the precision matrices and the corresponding adjacency matrices
for the different values of \eqn{(\lambda_1, \lambda_2)} can be found
\item{\code{Theta}}{A list with the estimated precision matrices \eqn{\{ \hat{\Theta}_i(\lambda_1, \lambda_2) \}_{i = 1}^m},
(only if \code{minimal = FALSE})}
\item{\code{adj_matrices}}{A list with the estimated adjacency matrices corresponding to the
estimated precision matrices in \code{Theta}. The entries
are \code{1} if there is an edge, \code{0} otherwise.
The matrices are sparse using package \code{\link[Matrix]{Matrix}}}
In addition, the input given to the CVN function is stored in the object as well:
\item{\code{Sigma}}{Empirical covariance matrices \eqn{\{\hat{\Sigma}_i\}_{i = 1}^m},
(only if \code{minimal = FALSE})}
\item{\code{m}}{Number of graphs}
\item{\code{p}}{Number of variables}
\item{\code{n_obs}}{Vector of length \eqn{m} with number of observations for each graph}
\item{\code{data}}{The \code{data}, but then normalized or centered (only if \code{minimal = FALSE})}
\item{\code{W}}{The \eqn{(m \times m)}-dimensional weight matrix \eqn{W}}
\item{\code{maxiter}}{Maximum number of iterations for the ADMM}
\item{\code{rho}}{The \eqn{\rho} ADMM's penalty parameter}
\item{\code{eps}}{The stopping criterion \eqn{\epsilon}}
\item{\code{truncate}}{Truncation value for \eqn{\{ \hat{\Theta}_i \}_{i = 1}^m}}
\item{\code{maxiter_genlasso}}{Maximum number of iterations for the generalized LASSO}
\item{\code{rho_genlasso}}{The \eqn{\rho} generalized LASSO penalty parameter}
\item{\code{eps_genlasso}}{The stopping criterion \eqn{\epsilon} for the generalized LASSO}
\item{\code{truncate_genlasso}}{Truncation value for \eqn{\beta} of the generalized LASSO}
\item{\code{n_lambda_values}}{Total number of \eqn{(\lambda_1, \lambda_2)} value combinations}
\item{\code{normalized}}{If \code{TRUE}, \code{data} was normalized. Otherwise \code{data} was only centered}
\item{\code{warmstart}}{If \code{TRUE}, warmstart was used}
\item{\code{minimal}}{If \code{TRUE}, \code{data}, \code{Theta} and \code{Sigma} are not added}
\item{\code{hits_border_aic}}{If \code{TRUE}, the optimal model based on the AIC hits the border of \eqn{(\lambda_1, \lambda_2)}}
\item{\code{hits_border_bic}}{If \code{TRUE}, the optimal model based on the BIC hits the border of \eqn{(\lambda_1, \lambda_2)}}
\item{\code{gamma_ebic}}{Gamma value used to calculate eBIC}
}
\description{
Estimates a covariate-varying network model (CVN), i.e., \eqn{m}
Gaussian graphical models that change with (multiple) external covariate(s).
The smoothing between the graphs is specified by the \eqn{(m \times m)}-dimensional
weight matrix \eqn{W}. The function returns the estimated precision matrices
for each graph.
}
\section{Reusing Estimates}{
 When estimating the graph for different values of
\eqn{\lambda_1} and \eqn{\lambda_2}, we use the graph estimated (if available)
for other \eqn{\lambda_1} and \eqn{\lambda_2} values closest to them.
}

\examples{
data(grid)

#' Choice of the weight matrix W. Each of 2 covariates has 3 categories
#' (uniform random)
W <- create_weight_matrix("uniform-random", k = 3, l = 3)

# lambdas:
lambda1 = 1  # can also be lambda1 = 1:2 
lambda2 = 1

(fit <- CVN(data = grid, 
            W = W, 
            lambda1 = lambda1, lambda2 = lambda2, 
            n_cores = 1,
            eps = 1e-2, maxiter = 200, # fast but imprecise
            verbose = TRUE))
}

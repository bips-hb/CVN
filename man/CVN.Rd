% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CVN.R, R/zzz.R
\docType{package}
\name{CVN}
\alias{CVN}
\title{Estimating a Covariate-Varying Network (CVN)}
\usage{
CVN(
  data,
  W,
  lambda1 = 1:10,
  lambda2 = 1:10,
  rho = 1,
  rho_genlasso = 1,
  eps = 1e-05,
  maxiter = 100,
  truncate = 1e-05,
  eps_genlasso = 1e-10,
  maxiter_genlasso = 100,
  truncate_genlasso = 1e-04,
  n_cores = 1,
  normalized = FALSE,
  warmstart = FALSE,
  use_previous_estimate = FALSE,
  use_genlasso_package = FALSE,
  verbose = FALSE
)
}
\arguments{
\item{data}{A list with matrices, each entry associated with a single graph. 
The number of columns should be the same for each matrix. 
Number of observations can differ}

\item{W}{The \eqn{(m \times m)}-dimensional symmetric 
weight matrix \eqn{W}}

\item{lambda1}{Vector with different \eqn{\lambda_1} LASSO penalty terms 
(Default: \code{1:10})}

\item{lambda2}{Vector with different \eqn{\lambda_2} global smoothing parameter values 
(Default: \code{1:10})}

\item{rho}{The \eqn{\rho} penalty parameter for the global ADMM algorithm (Default: \code{1})}

\item{rho_genlasso}{The \eqn{\rho} penalty parameter for the ADMM algorithm 
used to solve the generalized LASSO (Default: \code{1})}

\item{eps}{If the relative difference between two update steps is 
smaller than \eqn{\epsilon}, the algorithm stops. 
See \code{\link{relative_difference_precision_matrices}}
(Default: \code{1e-5})}

\item{maxiter}{Maximum number of iterations (Default: \code{100})}

\item{truncate}{All values of the final \eqn{\hat{\Theta}_i}'s below \code{truncate} will be 
set to \code{0}. (Default: \code{1e-5})}

\item{eps_genlasso}{If the relative difference between two update steps is 
smaller than \eqn{\epsilon}, the algorithm stops. 
(Default: \code{1e-10})}

\item{maxiter_genlasso}{Maximum number of iterations for solving 
the generalized LASSO problem (Default: \code{100})}

\item{truncate_genlasso}{All values of the final \eqn{\hat{\beta}} below 
\code{truncate_genlasso} will be set to \code{0}. 
(Default: \code{1e-4})}

\item{n_cores}{Number of cores used (Default: \code{1})}

\item{normalized}{Data is normalized if \code{TRUE}. Otherwise the data is only
centered (Default: \code{FALSE})}

\item{warmstart}{If \code{TRUE}, use the \code{\link[huge]{huge}} package for estimating
the individual graphs first (Default: \code{FALSE})}

\item{use_previous_estimate}{If \code{TRUE}, the estimated graph found for the previous 
values of \eqn{\lambda_1} and \eqn{\lambda_2} is used as starting point
for the next estimate (Default: \code{TRUE})}

\item{verbose}{Verbose (Default: \code{FALSE})}

\item{use_genlasso}{If \code{TRUE}, use the \code{genlasso} package in 
the \eqn{Z}-update step, rather then the ADMM (Default: \code{FALSE})}
}
\value{
A \code{CVN} object containing the estimates for all the graphs 
   for each different value of \eqn{(\lambda_1, \lambda_2)}. General results for 
   the different values of \eqn{(\lambda_1, \lambda_2)} can be found in the data frame
   \code{results}. It consists of multiple columns, namely: 
   \item{\code{lambda1}}{\eqn{\lambda_1} value}
   \item{\code{lambda2}}{\eqn{\lambda_1} value}
   \item{\code{converged}}{whether algorithm converged or not}
   \item{\code{value}}{value of the negative log-likelihood function}
   \item{\code{n_iterations}}{number of iterations of the ADMM}
   \item{\code{aic}}{Aikake information criteration}
   \item{\code{id}}{The id. This corresponds to the indices of the lists}
   In addition, the results of for the different values of \eqn{(\lambda_1, \lambda_2)}
   can be found in the following lists: 
   \item{\code{Theta}}{The estimated precision matrices \eqn{\{ \hat{\Theta}_i \}_{i = 1}^m}}
   \item{\code{adj_matrices}}{The estimated adjacency matrices; 
                        \code{1} if there is an edge, \code{0} otherwise. 
                        Matrices are sparse using package \code{\link[Matrix]{Matrix}}}
   \item{\code{Sigma}}{Empirical covariance matrices \eqn{\{\hat{\Sigma}_i\}_{i = 1}^m}}
   \item{\code{m}}{Number of graphs}
   \item{\code{p}}{Number of variables}
   \item{\code{n_obs}}{Vector of length \eqn{m} with number of observations for each graph}
  \item{\code{data}}{The \code{data}, but then normalized or centered}
  \item{\code{normalized}}{If \code{TRUE}, \code{data} was normalized. Otherwise \code{data} was only centered}
  \item{\code{W}}{The \eqn{(m \times m)}-dimensional weight matrix \eqn{W}}
  \item{\code{D}}{Matrix \eqn{D} used for the Generalized LASSO}
  \item{\code{lambda1}}{The \eqn{\lambda_1} LASSO penalty term}
  \item{\code{lambda2}}{The \eqn{\lambda_2} global smoothing parameter} 
  \item{\code{rho}}{The \eqn{\rho} ADMM's penalty parameter} 
  \item{\code{epsilon}}{The stopping criterion \eqn{\epsilon}} 
  \item{\code{converged}}{If \code{TRUE}, stopping condition has been met; \code{FALSE} otherwise}
  \item{\code{value}}{The final relative difference}
  \item{\code{n_iterations}}{Number of iterations}
  \item{\code{truncate}}{Truncation value for \eqn{\{ \hat{\Theta}_i \}_{i = 1}^m}}
}
\description{
Estimates a covariate-varying network model (CVN), i.e., \eqn{m} 
Gaussian graphical models that change with (multiple) external covariate(s). 
The smoothing between the graphs is specified by the \eqn{(m \times m)}-dimensional
weight matrix \eqn{W}. The function returns the estimated precision matrices 
for each graph.

An estimator for graphical models changing with multiple discrete
external covariates
}
\section{Reusing Estimates}{
 When estimating the graph for different values of 
\eqn{\lambda_1} and \eqn{\lambda_2}, we use the graph estimated (if available) 
for other \eqn{\lambda_1} and \eqn{\lambda_2} values closest to them.
}

\examples{
data(grid)
m <- 9 # must be 9 for this example

#' Choice of the weight matrix W. 
#' (uniform random) 
W <- matrix(runif(m*m), ncol = m)
W <- W \%*\% t(W)
W <- W / max(W)
diag(W) <- 0

# lambdas:
lambda1 = 1:2
lambda2 = 1:2

(cvn <- CVN::CVN(grid, W, lambda1 = lambda1, lambda2 = lambda2, eps = 1e-3, maxiter = 1000, verbose = TRUE))
}
\author{
Louis Dijkstra
}

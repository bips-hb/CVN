% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CVN.R, R/zzz.R
\docType{package}
\name{CVN}
\alias{CVN}
\title{Estimating a Covariate-Varying Network (CVN)}
\usage{
CVN(
  data,
  W,
  lambda1 = 1:2,
  lambda2 = 1:2,
  rho = 1,
  eps = 1e-04,
  maxiter = 100,
  truncate = 1e-05,
  rho_genlasso = 1,
  eps_genlasso = 1e-10,
  maxiter_genlasso = 100,
  truncate_genlasso = 1e-04,
  n_cores = min(length(lambda1) * length(lambda2), parallel::detectCores() - 1),
  normalized = FALSE,
  warmstart = TRUE,
  use_genlasso_package = FALSE,
  minimal = FALSE,
  verbose = TRUE,
  use_new_updateZ = TRUE
)
}
\arguments{
\item{data}{A list with matrices, each entry associated with a single graph. 
The number of columns should be the same for each matrix. 
Number of observations can differ}

\item{W}{The \eqn{(m \times m)}-dimensional symmetric 
weight matrix \eqn{W}}

\item{lambda1}{Vector with different \eqn{\lambda_1} LASSO penalty terms 
(Default: \code{1:2})}

\item{lambda2}{Vector with different \eqn{\lambda_2} global smoothing parameter values 
(Default: \code{1:2})}

\item{rho}{The \eqn{\rho} penalty parameter for the global ADMM algorithm (Default: \code{1})}

\item{eps}{If the relative difference between two update steps is 
smaller than \eqn{\epsilon}, the algorithm stops. 
See \code{\link{relative_difference_precision_matrices}}
(Default: \code{1e-4})}

\item{maxiter}{Maximum number of iterations (Default: \code{100})}

\item{truncate}{All values of the final \eqn{\hat{\Theta}_i}'s below \code{truncate} will be 
set to \code{0}. (Default: \code{1e-5})}

\item{rho_genlasso}{The \eqn{\rho} penalty parameter for the ADMM algorithm 
used to solve the generalized LASSO (Default: \code{1})}

\item{eps_genlasso}{If the relative difference between two update steps is 
smaller than \eqn{\epsilon}, the algorithm stops. 
(Default: \code{1e-10})}

\item{maxiter_genlasso}{Maximum number of iterations for solving 
the generalized LASSO problem (Default: \code{100})}

\item{truncate_genlasso}{All values of the final \eqn{\hat{\beta}} below 
\code{truncate_genlasso} will be set to \code{0}. 
(Default: \code{1e-4})}

\item{n_cores}{Number of cores used (Default: max. number of cores - 1, or 
the total number penalty term pairs if that is less)}

\item{normalized}{Data is normalized if \code{TRUE}. Otherwise the data is only
centered (Default: \code{FALSE})}

\item{warmstart}{If \code{TRUE}, use the \code{\link[huge]{huge}} package for estimating
the individual graphs first (Default: \code{TRUE})}

\item{minimal}{If \code{TRUE}, the returned \code{cvn} is minimal in terms of 
memory, i.e., \code{Theta}, \code{data} and \code{Sigma} are not 
returned (Default: \code{FALSE})}

\item{verbose}{Verbose (Default: \code{TRUE})}

\item{use_genlasso}{If \code{TRUE}, use the \code{genlasso} package in 
the \eqn{Z}-update step, rather then the ADMM (Default: \code{FALSE})}
}
\value{
A \code{CVN} object containing the estimates for all the graphs 
   for each different value of \eqn{(\lambda_1, \lambda_2)}. General results for 
   the different values of \eqn{(\lambda_1, \lambda_2)} can be found in the data frame
   \code{results}. It consists of multiple columns, namely: 
   \item{\code{lambda1}}{\eqn{\lambda_1} value}
   \item{\code{lambda2}}{\eqn{\lambda_1} value}
   \item{\code{converged}}{whether algorithm converged or not}
   \item{\code{value}}{value of the negative log-likelihood function}
   \item{\code{n_iterations}}{number of iterations of the ADMM}
   \item{\code{aic}}{Aikake information criteration}
   \item{\code{id}}{The id. This corresponds to the indices of the lists}
   The estimates of the precision matrices and the corresponding adjacency matrices
   for the different values of \eqn{(\lambda_1, \lambda_2)} can be found 
   \item{\code{Theta}}{A list with the estimated precision matrices \eqn{\{ \hat{\Theta}_i(\lambda_1, \lambda_2) \}_{i = 1}^m}, 
                       (only if \code{minimal = FALSE})}
   \item{\code{adj_matrices}}{A list with the estimated adjacency matrices corresponding to the 
                              estimated precision matrices in \code{Theta}. The entries 
                              are \code{1} if there is an edge, \code{0} otherwise. 
                              The matrices are sparse using package \code{\link[Matrix]{Matrix}}}
   In addition, the input given to the CVN function is stored in the object as well:
   \item{\code{Sigma}}{Empirical covariance matrices \eqn{\{\hat{\Sigma}_i\}_{i = 1}^m}, 
                             (only if \code{minimal = FALSE})}
   \item{\code{m}}{Number of graphs}
   \item{\code{p}}{Number of variables}
   \item{\code{n_obs}}{Vector of length \eqn{m} with number of observations for each graph}
  \item{\code{data}}{The \code{data}, but then normalized or centered (only if \code{minimal = FALSE})}
  \item{\code{W}}{The \eqn{(m \times m)}-dimensional weight matrix \eqn{W}}
  \item{\code{maxiter}}{Maximum number of iterations for the ADMM}
  \item{\code{rho}}{The \eqn{\rho} ADMM's penalty parameter} 
  \item{\code{eps}}{The stopping criterion \eqn{\epsilon}} 
  \item{\code{truncate}}{Truncation value for \eqn{\{ \hat{\Theta}_i \}_{i = 1}^m}}
  \item{\code{maxiter_genlasso}}{Maximum number of iterations for the generarlzed LASSO}
  \item{\code{rho_genlasso}}{The \eqn{\rho} generalized LASSO penalty parameter} 
  \item{\code{eps_genlasso}}{The stopping criterion \eqn{\epsilon} for the generalized LASSO} 
  \item{\code{truncate_genlasso}}{Truncation value for \eqn{\beta} of the generalized LASSO}
  \item{\code{n_lambda_values}}{Total number of \eqn{(\lambda_1, \lambda_2)} value combinations}
  \item{\code{normalized}}{If \code{TRUE}, \code{data} was normalized. Otherwise \code{data} was only centered}
  \item{\code{warmstart}}{If \code{TRUE}, warmstart was used}
  \item{\code{use_genlasso_package}}{If \code{TRUE}, the \code{\link[genlasso]{genlasso}}
            package is used instead of the ADMM algorithm}
  \item{\code{minimal}}{If \code{TRUE}, \code{data}, \code{Theta} and \code{Sigma} are not added}
}
\description{
Estimates a covariate-varying network model (CVN), i.e., \eqn{m} 
Gaussian graphical models that change with (multiple) external covariate(s). 
The smoothing between the graphs is specified by the \eqn{(m \times m)}-dimensional
weight matrix \eqn{W}. The function returns the estimated precision matrices 
for each graph.

An estimator for graphical models changing with multiple discrete
external covariates
}
\section{Reusing Estimates}{
 When estimating the graph for different values of 
\eqn{\lambda_1} and \eqn{\lambda_2}, we use the graph estimated (if available) 
for other \eqn{\lambda_1} and \eqn{\lambda_2} values closest to them.
}

\examples{
data(grid)
m <- 9 # must be 9 for this example

#' Choice of the weight matrix W. 
#' (uniform random) 
W <- matrix(runif(m*m), ncol = m)
W <- W \%*\% t(W)
W <- W / max(W)
diag(W) <- 0

# lambdas:
lambda1 = 1:2
lambda2 = 1:2

(cvn <- CVN::CVN(grid, W, lambda1 = lambda1, lambda2 = lambda2, eps = 1e-3, maxiter = 1000, verbose = TRUE))
}
\author{
Louis Dijkstra
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CVN.R
\name{CVN}
\alias{CVN}
\title{Estimating a Covariate-Varying Network (CVN)}
\usage{
CVN(
  data,
  W,
  lambda1 = 1:2,
  lambda2 = 1:2,
  gamma1 = NULL,
  gamma2 = NULL,
  rho = 1,
  eps = 1e-04,
  maxiter = 100,
  truncate = 1e-05,
  rho_genlasso = 1,
  eps_genlasso = 1e-10,
  maxiter_genlasso = 100,
  truncate_genlasso = 1e-04,
  n_cores = min(length(lambda1) * length(lambda2), parallel::detectCores() - 1),
  normalized = FALSE,
  warmstart = TRUE,
  minimal = FALSE,
  verbose = TRUE
)
}
\arguments{
\item{data}{A list with matrices, each entry associated with a single graph. 
The number of columns should be the same for each matrix. 
Number of observations can differ}

\item{W}{The \eqn{(m \times m)}-dimensional symmetric 
weight matrix \eqn{W}}

\item{lambda1}{Vector with different \eqn{\lambda_1}. LASSO penalty terms 
(Default: \code{1:2})}

\item{lambda2}{<- Vector with different \eqn{\lambda_2}. The global smoothing parameter values 
(Default: \code{1:2})}

\item{gamma1}{A vector of \eqn{\gamma_1}'s LASSO penalty terms, where 
\eqn{\gamma_1 = \frac{2 \lambda_1}{m p (1 - p)}}. If \code{gamma1} 
is set, the value of \code{lambda1} is ignored. (Default: \code{NULL}).}

\item{gamma2}{A vector of \eqn{\gamma_2}'s global smoothing parameters, where
that \eqn{\gamma_2 = \frac{4 \lambda_2}{m(m-1)p(p-1)}}. If \code{gamma2} 
is set, the value of \code{lambda2} is ignored.(Default: \code{NULL}).}

\item{rho}{The \eqn{\rho} penalty parameter for the global ADMM algorithm (Default: \code{1})}

\item{eps}{If the relative difference between two update steps is 
smaller than \eqn{\epsilon}, the algorithm stops. 
See \code{\link{relative_difference_precision_matrices}}
(Default: \code{1e-4})}

\item{maxiter}{Maximum number of iterations (Default: \code{100})}

\item{truncate}{All values of the final \eqn{\hat{\Theta}_i}'s below \code{truncate} will be 
set to \code{0}. (Default: \code{1e-5})}

\item{rho_genlasso}{The \eqn{\rho} penalty parameter for the ADMM algorithm 
used to solve the generalized LASSO (Default: \code{1})}

\item{eps_genlasso}{If the relative difference between two update steps is 
smaller than \eqn{\epsilon}, the algorithm stops. 
(Default: \code{1e-10})}

\item{maxiter_genlasso}{Maximum number of iterations for solving 
the generalized LASSO problem (Default: \code{100})}

\item{truncate_genlasso}{All values of the final \eqn{\hat{\beta}} below 
\code{truncate_genlasso} will be set to \code{0}. 
(Default: \code{1e-4})}

\item{n_cores}{Number of cores used (Default: max. number of cores - 1, or 
the total number penalty term pairs if that is less)}

\item{normalized}{Data is normalized if \code{TRUE}. Otherwise the data is only
centered (Default: \code{FALSE})}

\item{warmstart}{If \code{TRUE}, use the \code{\link[huge]{huge}} package for estimating
the individual graphs first (Default: \code{TRUE})}

\item{minimal}{If \code{TRUE}, the returned \code{cvn} is minimal in terms of 
memory, i.e., \code{Theta}, \code{data} and \code{Sigma} are not 
returned (Default: \code{FALSE})}

\item{verbose}{Verbose (Default: \code{TRUE})}
}
\value{
A \code{CVN} object containing the estimates for all the graphs 
   for each different value of \eqn{(\lambda_1, \lambda_2)}. General results for 
   the different values of \eqn{(\lambda_1, \lambda_2)} can be found in the data frame
   \code{results}. It consists of multiple columns, namely: 
   \item{\code{lambda1}}{\eqn{\lambda_1} value}
   \item{\code{lambda2}}{\eqn{\lambda_2} value}
   \item{\code{converged}}{whether algorithm converged or not}
   \item{\code{value}}{value of the negative log-likelihood function}
   \item{\code{n_iterations}}{number of iterations of the ADMM}
   \item{\code{aic}}{Aikake information criterion}
   \item{\code{gamma1}}{\eqn{\gamma_1} value}
   \item{\code{gamma2}}{\eqn{\gamma_2} value}
   \item{\code{id}}{The id. This corresponds to the indices of the lists}
   \item{\code{bic}}{Bayesian information criterion}
   The estimates of the precision matrices and the corresponding adjacency matrices
   for the different values of \eqn{(\lambda_1, \lambda_2)} can be found 
   \item{\code{Theta}}{A list with the estimated precision matrices \eqn{\{ \hat{\Theta}_i(\lambda_1, \lambda_2) \}_{i = 1}^m}, 
                       (only if \code{minimal = FALSE})}
   \item{\code{adj_matrices}}{A list with the estimated adjacency matrices corresponding to the 
                              estimated precision matrices in \code{Theta}. The entries 
                              are \code{1} if there is an edge, \code{0} otherwise. 
                              The matrices are sparse using package \code{\link[Matrix]{Matrix}}}
   In addition, the input given to the CVN function is stored in the object as well:
   \item{\code{Sigma}}{Empirical covariance matrices \eqn{\{\hat{\Sigma}_i\}_{i = 1}^m}, 
                             (only if \code{minimal = FALSE})}
   \item{\code{m}}{Number of graphs}
   \item{\code{p}}{Number of variables}
   \item{\code{n_obs}}{Vector of length \eqn{m} with number of observations for each graph}
  \item{\code{data}}{The \code{data}, but then normalized or centered (only if \code{minimal = FALSE})}
  \item{\code{W}}{The \eqn{(m \times m)}-dimensional weight matrix \eqn{W}}
  \item{\code{maxiter}}{Maximum number of iterations for the ADMM}
  \item{\code{rho}}{The \eqn{\rho} ADMM's penalty parameter} 
  \item{\code{eps}}{The stopping criterion \eqn{\epsilon}} 
  \item{\code{truncate}}{Truncation value for \eqn{\{ \hat{\Theta}_i \}_{i = 1}^m}}
  \item{\code{maxiter_genlasso}}{Maximum number of iterations for the generarlzed LASSO}
  \item{\code{rho_genlasso}}{The \eqn{\rho} generalized LASSO penalty parameter} 
  \item{\code{eps_genlasso}}{The stopping criterion \eqn{\epsilon} for the generalized LASSO} 
  \item{\code{truncate_genlasso}}{Truncation value for \eqn{\beta} of the generalized LASSO}
  \item{\code{n_lambda_values}}{Total number of \eqn{(\lambda_1, \lambda_2)} value combinations}
  \item{\code{normalized}}{If \code{TRUE}, \code{data} was normalized. Otherwise \code{data} was only centered}
  \item{\code{warmstart}}{If \code{TRUE}, warmstart was used}
  \item{\code{minimal}}{If \code{TRUE}, \code{data}, \code{Theta} and \code{Sigma} are not added}
  \item{\code{hits_border_aic}}{If \code{TRUE}, the optimal model based on the AIC hits the border of \eqn{(\lambda_1, \lambda_2)}}
  \item{\code{hits_border_bic}}{If \code{TRUE}, the optimal model based on the BIC hits the border of \eqn{(\lambda_1, \lambda_2)}}
}
\description{
Estimates a covariate-varying network model (CVN), i.e., \eqn{m} 
Gaussian graphical models that change with (multiple) external covariate(s). 
The smoothing between the graphs is specified by the \eqn{(m \times m)}-dimensional
weight matrix \eqn{W}. The function returns the estimated precision matrices 
for each graph.
}
\section{Reusing Estimates}{
 When estimating the graph for different values of 
\eqn{\lambda_1} and \eqn{\lambda_2}, we use the graph estimated (if available) 
for other \eqn{\lambda_1} and \eqn{\lambda_2} values closest to them.
}

\examples{
data(grid)
m <- 9 # must be 9 for this example

#' Choice of the weight matrix W. 
#' (uniform random) 
W <- matrix(runif(m*m), ncol = m)
W <- W \%*\% t(W)
W <- W / max(W)
diag(W) <- 0

# lambdas:
lambda1 = 1  # can also be lambda1 = 1:2 
lambda2 = 1

(cvn <- CVN::CVN(grid, W, lambda1 = lambda1, lambda2 = lambda2, 
                 eps = 1e-3, maxiter = 1000, verbose = TRUE))
}
